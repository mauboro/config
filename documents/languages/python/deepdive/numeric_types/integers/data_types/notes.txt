I'll start this note by saying that how large a number can be depends interely on how many bits can be used to store it. Computer memory works by using bits to store information, any piece of discrete information is represented in a binary form of base 2, this means that every number expressed has to to fit in the total of bits that can be used to store it. The computation behind it states that if an N number of bits to store certain information, there can be 2**N total combinations that can be expressed. Some languages, like Java, provide multiple distinct integer data types that used a fixed number of bits, those are: the byte(signed 8 bit numbers, range=(-128, 127)), the short(signed 16 bit numbers, range=(-32.368, 32.367)), the int(signed 32 bit numbers, range=(-2**31, 2**31 - 1)) and the long(signed 64 bits, range=(-2**63, 2**63 - 1)). However, Python does not work that way, the int storing method uses a variable number number of bits. It can use 8, 16, 32, or 64 bits and it decides how many bits to use based on the value referenced by the newly written variable. The process is seamless to us mere humans and the limitations of representing a given numbers are completely related to the available memory(or, if you are a nerd, the quantity of bits). The fact that larger numbers take more memory space to be stored is obvious and therefore operators like + and - with those numbers will take more time to be computed. It is important to note that since everything in Python is an object, there is an inherent memory overhead that comes withe process of object's instantiation.

